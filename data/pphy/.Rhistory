#####
# Imbalanced Model
splitIndex <- caret::createDataPartition(conglomerate$min, p =.7,
list = FALSE,
times = 1)
trainSPlit <- conglomerate[splitIndex,]
testSplit <- conglomerate[-splitIndex,]
imbal_minModel <- randomForest(min ~ .,
trainSPlit,
proximity = TRUE,
ntree = 500, localImp = TRUE)
print(imbal_minModel)
plot(imbal_minModel)
par(pty = 's')
plot.roc(trainSPlit$min, imbal_minModel$votes[,1],legacy.axes=TRUE,
percent = FALSE, print.auc = TRUE,xlab="FALSE POSITIVE",
ylab = 'TRUE POSITIVE')
par(pty = 'm')
# Balanced Model
splitIndex <- caret::createDataPartition(df_smote$min, p =.7,
list = FALSE,
times = 1)
trainSPlit <- df_smote[splitIndex,]
testSplit <- df_smote[-splitIndex,]
round(prop.table(table(trainSPlit$min)),digits = 3)
round(prop.table(table(testSplit$min)),digits = 3)
ctrl <- caret::trainControl(method = 'cv',
number = 10,
verboseIter = TRUE)
tg <- data.frame(mtry = seq(2,12, by = 1))
minModel <- randomForest(min ~ .,
trainSPlit,
proximity = TRUE,
ntree = 500, localImp = TRUE)
# minModel <- caret::train(min ~ ., data = trainSPlit, method = "rf",
#                          trControl = ctrl, ntree = 300, importance = TRUE,
#                          tuneGrid = tg, proximity = TRUE)
print(minModel)
plot(minModel)
par(pty = 's')
plot.roc(trainSPlit$min, minModel$votes[,1],legacy.axes=TRUE,
percent = FALSE, print.auc = TRUE,xlab="FALSE POSITIVE",
ylab = 'TRUE POSITIVE')
par(pty = 'm')
pred <- predict(minModel, testSplit[,-12])
confusionMatrix(as.factor(testSplit$min), pred,positive = 'ORE')
varImpPlot(minModel,sort = TRUE,scale = TRUE)
varImp(minModel,sort = TRUE,scale = TRUE)
x <- df %>%
filter(ROCK == 'CONGLOMERATE')
y <- df %>%
filter(ROCK == 'CONGLOMERATE') %>%
select(min)
labs <- df %>%
filter(ROCK == 'CONGLOMERATE') %>%
select(ID:LITHO)
pred1 <- predict(minModel, x)
confusionMatrix(as.factor(y$min), as.factor(pred1),positive = 'ORE')
auc1 <- roc(as.double(y$min), as.double(pred1))
plot(auc1, ylim = c(0,1), print.thres = TRUE, main = paste('AUC',round(auc1$auc[[1]],2)))
abline(h=1,col='blue',lwd=2)
abline(h=0,col='red',lwd=2)
## Start by converting the proximity matrix into a distance matrix.
distance.matrix <- as.dist(1-minModel$proximity)
mds.stuff <- cmdscale(distance.matrix, eig=TRUE, x.ret=TRUE)
## calculate the percentage of variation that each MDS axis accounts for...
mds.var.per <- round(mds.stuff$eig/sum(mds.stuff$eig)*100, 1)
## now make a fancy looking plot that shows the MDS axes and the variation:
mds.values <- mds.stuff$points
mds.data <- data.frame(Sample=rownames(mds.values),
X=mds.values[,1],
Y=mds.values[,2],
Status = trainSPlit$min)
ggplot(data=mds.data, aes(x=X, y=Y, label=Sample)) +
geom_point(aes(col = Status)) +
# theme_bw() +
xlab(paste("MDS1 - ", mds.var.per[1], "%", sep="")) +
ylab(paste("MDS2 - ", mds.var.per[2], "%", sep="")) +
ggtitle("MDS plot using (1 - Random Forest Proximities)")
#####
# Random Forest Classification of Mineralized Samples
#
# version: 1.0 (2020/11/26)
#
# Last modifications:
#
# -----
#
#
#
# -----
# Guilherme Ferreira, (guilherme.ferreira@cprm.gov.br)
# November, 2020
#####
#####
# Setting up the enviroment
#####
setwd('~/GitHub/jacobina/data/pphy')
set.seed(42)
#####
# Import Packages
#####
library(tidyverse) # ggplot2, tidyr, dplyr
library(readxl) # open XLSX data
library(geoquimica) # Data wrangling
library(DMwR) # SMOTE
library(caret) # Machine Learning
library(randomForest) # RF
library(randomForestExplainer) # RF
library(pROC) # ROC and AUC
library(ElemStatLearn)
library(smotefamily)
#####
# Data Preparation
#####
# pXRF data ----
xrf <- read_xlsx(path = '~/GitHub/jacobina/data/xrf/pXRF_Jacobina_SAMPLES.xlsx', sheet = 1)
# Petrophysics data ----
files <- list.files(pattern = '.xlsx$',path = '~/GitHub/jacobina/data/pphy')
phy <- lapply(files, read_xlsx, sheet = 1) %>%
bind_rows() %>%
mutate(HOLE = as.factor(HOLE),
ID = as.factor(ID),
FROM = as.numeric(FROM),
TO = as.numeric(TO),
LITHO = as.factor(LITHO),
MINERALIZATION = as.factor(MINERALIZATION),
SUSCEPTIBILITY = as.numeric(SUSCEPTIBILITY),
CONDUCTIVITY = as.numeric(CONDUCTIVITY),
DENSITY = as.numeric(DENSITY),
COMMENTS = as.character(COMMENTS)) %>%
arrange(ID)
phy <- phy %>%
mutate(SAMPLE = paste(HOLE,formatC(x = phy$FROM,flag = '0',
width = 6,
digits = 2,
format = 'f'),sep = '-'),
ROCK = case_when(phy$LITHO %in% c('GRIT','LMPC','LVLPC','MLPC','MPC','MSPC',
'SMPC','SPC','VSPC') ~ 'CONGLOMERATE',
phy$LITHO %in% c('QTO','QTO_SX','QZ_VEIN') ~ 'QUARTZITE',
phy$LITHO %in% c('ITV','UMF') ~ 'ULTRAMAFIC',
phy$LITHO %in% c('BRX') ~ 'BRECCIA',
phy$LITHO %in% c('XISTO') ~ 'SCHIST',
phy$LITHO %in% c('SOLO') ~ 'SOIL',
TRUE ~ as.character(phy$LITHO)))
# Merging dataset ----
df <- phy %>%
left_join(xrf,by = 'SAMPLE') %>%
mutate(min = factor(ifelse(test = phy$MINERALIZATION == 1 | phy$MINERALIZATION == 1000,
yes = 'ORE', no =  'BARREN')))
df %>%
select(min, SUSCEPTIBILITY,CONDUCTIVITY, DENSITY, Cu, Fe, Cr, Ti, K, Al, Si, S) %>%
elem_norm(method = 'clr') %>%
GGally::ggpairs(mapping=ggplot2::aes(colour = min))
# Filtering for Conglomerate only ----
conglomerate <- as.data.frame(df) %>%
na.omit() %>%
filter(ROCK == 'CONGLOMERATE') %>%
select(min,7:9, Cu, Fe, Cr, Ti, K, Al, Si, S)
# Split data to smote
index <- caret::createDataPartition(conglomerate$min, p =.7,
list = FALSE,
times = 1)
toSmote <- conglomerate[index,]
## Smote
# df_smote <- DMwR::SMOTE(form = min ~ .,
#                         data = as.data.frame(toSmote),
#                         perc.over = 200,
#                         perc.under = 150,
#                         k = 5)
fromSmote <- BLSMOTE(dupSize = 0, X = as.data.frame(toSmote[,-1]),K = 5,target = as.data.frame(toSmote[,'min']))
fromSmote$data %>%
rename(min = class) %>%
elem_norm(method = 'clr') %>%
GGally::ggpairs(mapping=ggplot2::aes(colour = min))
df_smote <- fromSmote$data %>%
rename(min = class) %>%
mutate(min = as.factor(min))
table(conglomerate$min)
table(toSmote$min)
table(df_smote$min)
#####
# Random Forest
#####
# Imbalanced Model
splitIndex <- caret::createDataPartition(conglomerate$min, p =.7,
list = FALSE,
times = 1)
trainSPlit <- conglomerate[splitIndex,]
testSplit <- conglomerate[-splitIndex,]
imbal_minModel <- randomForest(min ~ .,
trainSPlit,
proximity = TRUE,
ntree = 500, localImp = TRUE)
print(imbal_minModel)
plot(imbal_minModel)
par(pty = 's')
plot.roc(trainSPlit$min, imbal_minModel$votes[,1],legacy.axes=TRUE,
percent = FALSE, print.auc = TRUE,xlab="FALSE POSITIVE",
ylab = 'TRUE POSITIVE')
par(pty = 'm')
# Balanced Model
splitIndex <- caret::createDataPartition(df_smote$min, p =.7,
list = FALSE,
times = 1)
trainSPlit <- df_smote[splitIndex,]
testSplit <- df_smote[-splitIndex,]
round(prop.table(table(trainSPlit$min)),digits = 3)
round(prop.table(table(testSplit$min)),digits = 3)
ctrl <- caret::trainControl(method = 'cv',
number = 10,
verboseIter = TRUE)
tg <- data.frame(mtry = seq(2,12, by = 1))
minModel <- randomForest(min ~ .,
trainSPlit,
proximity = TRUE,
ntree = 500, localImp = TRUE)
# minModel <- caret::train(min ~ ., data = trainSPlit, method = "rf",
#                          trControl = ctrl, ntree = 300, importance = TRUE,
#                          tuneGrid = tg, proximity = TRUE)
print(minModel)
plot(minModel)
par(pty = 's')
plot.roc(trainSPlit$min, minModel$votes[,1],legacy.axes=TRUE,
percent = FALSE, print.auc = TRUE,xlab="FALSE POSITIVE",
ylab = 'TRUE POSITIVE')
par(pty = 'm')
pred <- predict(minModel, testSplit[,-12])
confusionMatrix(as.factor(testSplit$min), pred,positive = 'ORE')
varImpPlot(minModel,sort = TRUE,scale = TRUE)
varImp(minModel,sort = TRUE,scale = TRUE)
x <- df %>%
filter(ROCK == 'CONGLOMERATE')
y <- df %>%
filter(ROCK == 'CONGLOMERATE') %>%
select(min)
labs <- df %>%
filter(ROCK == 'CONGLOMERATE') %>%
select(ID:LITHO)
pred1 <- predict(minModel, x)
confusionMatrix(as.factor(y$min), as.factor(pred1),positive = 'ORE')
auc1 <- roc(as.double(y$min), as.double(pred1))
plot(auc1, ylim = c(0,1), print.thres = TRUE, main = paste('AUC',round(auc1$auc[[1]],2)))
abline(h=1,col='blue',lwd=2)
abline(h=0,col='red',lwd=2)
## Start by converting the proximity matrix into a distance matrix.
distance.matrix <- as.dist(1-minModel$proximity)
mds.stuff <- cmdscale(distance.matrix, eig=TRUE, x.ret=TRUE)
## calculate the percentage of variation that each MDS axis accounts for...
mds.var.per <- round(mds.stuff$eig/sum(mds.stuff$eig)*100, 1)
## now make a fancy looking plot that shows the MDS axes and the variation:
mds.values <- mds.stuff$points
mds.data <- data.frame(Sample=rownames(mds.values),
X=mds.values[,1],
Y=mds.values[,2],
Status = trainSPlit$min)
ggplot(data=mds.data, aes(x=X, y=Y, label=Sample)) +
geom_point(aes(col = Status)) +
# theme_bw() +
xlab(paste("MDS1 - ", mds.var.per[1], "%", sep="")) +
ylab(paste("MDS2 - ", mds.var.per[2], "%", sep="")) +
ggtitle("MDS plot using (1 - Random Forest Proximities)")
fromSmote <- BLSMOTE(dupSize = 90, X = as.data.frame(toSmote[,-1]),K = 5,target = as.data.frame(toSmote[,'min']))
fromSmote$data %>%
rename(min = class) %>%
elem_norm(method = 'clr') %>%
GGally::ggpairs(mapping=ggplot2::aes(colour = min))
df_smote <- fromSmote$data %>%
rename(min = class) %>%
mutate(min = as.factor(min))
table(conglomerate$min)
table(toSmote$min)
table(df_smote$min)
fromSmote <- BLSMOTE(dupSize = 2, X = as.data.frame(toSmote[,-1]),K = 5,target = as.data.frame(toSmote[,'min']))
df_smote <- fromSmote$data %>%
rename(min = class) %>%
mutate(min = as.factor(min))
table(conglomerate$min)
table(toSmote$min)
table(df_smote$min)
fromSmote <- BLSMOTE(C = 5,dupSize = 2,
X = as.data.frame(toSmote[,-1]),
K = 5,
target = as.data.frame(toSmote[,'min']))
df_smote <- fromSmote$data %>%
rename(min = class) %>%
mutate(min = as.factor(min))
table(conglomerate$min)
table(toSmote$min)
table(df_smote$min)
fromSmote <- BLSMOTE(C = 5,dupSize = 3,
X = as.data.frame(toSmote[,-1]),
K = 5,
target = as.data.frame(toSmote[,'min']))
table(conglomerate$min)
table(toSmote$min)
table(df_smote$min)
fromSmote <- BLSMOTE(C = 5,dupSize = 5,
X = as.data.frame(toSmote[,-1]),
K = 5,
target = as.data.frame(toSmote[,'min']))
table(df_smote$min)
table(toSmote$min)
df_smote <- fromSmote$data %>%
rename(min = class) %>%
mutate(min = as.factor(min))
table(df_smote$min)
fromSmote <- BLSMOTE(C = 5,dupSize = 0,
X = as.data.frame(toSmote[,-1]),
K = 5,
target = as.data.frame(toSmote[,'min']))
fromSmote$data %>%
rename(min = class) %>%
elem_norm(method = 'clr') %>%
GGally::ggpairs(mapping=ggplot2::aes(colour = min))
df_smote <- fromSmote$data %>%
rename(min = class) %>%
mutate(min = as.factor(min))
table(conglomerate$min)
table(toSmote$min)
table(df_smote$min)
splitIndex <- caret::createDataPartition(conglomerate$min, p =.7,
list = FALSE,
times = 1)
trainSPlit <- conglomerate[splitIndex,]
testSplit <- conglomerate[-splitIndex,]
imbal_minModel <- randomForest(min ~ .,
trainSPlit,
proximity = TRUE,
ntree = 500, localImp = TRUE)
print(imbal_minModel)
plot(imbal_minModel)
par(pty = 's')
plot.roc(trainSPlit$min, imbal_minModel$votes[,1],legacy.axes=TRUE,
percent = FALSE, print.auc = TRUE,xlab="FALSE POSITIVE",
ylab = 'TRUE POSITIVE')
par(pty = 'm')
splitIndex <- caret::createDataPartition(df_smote$min, p =.7,
list = FALSE,
times = 1)
trainSPlit <- df_smote[splitIndex,]
testSplit <- df_smote[-splitIndex,]
round(prop.table(table(trainSPlit$min)),digits = 3)
round(prop.table(table(testSplit$min)),digits = 3)
ctrl <- caret::trainControl(method = 'cv',
number = 10,
verboseIter = TRUE)
tg <- data.frame(mtry = seq(2,12, by = 1))
minModel <- randomForest(min ~ .,
trainSPlit,
proximity = TRUE,
ntree = 500, localImp = TRUE)
print(minModel)
plot(minModel)
par(pty = 's')
plot.roc(trainSPlit$min, minModel$votes[,1],legacy.axes=TRUE,
percent = FALSE, print.auc = TRUE,xlab="FALSE POSITIVE",
ylab = 'TRUE POSITIVE')
par(pty = 'm')
pred <- predict(minModel, testSplit[,-12])
confusionMatrix(as.factor(testSplit$min), pred,positive = 'ORE')
varImpPlot(minModel,sort = TRUE,scale = TRUE)
varImp(minModel,sort = TRUE,scale = TRUE)
x <- df %>%
filter(ROCK == 'CONGLOMERATE')
fromSmote <- BLSMOTE(C = 5,dupSize = 2,
X = as.data.frame(toSmote[,-1]),
K = 5,
target = as.data.frame(toSmote[,'min']))
df_smote <- fromSmote$data %>%
rename(min = class) %>%
mutate(min = as.factor(min))
df_smote <- fromSmote$data %>%
rename(min = class) %>%
mutate(min = as.factor(min))
table(conglomerate$min)
table(toSmote$min)
table(df_smote$min)
splitIndex <- caret::createDataPartition(conglomerate$min, p =.7,
list = FALSE,
times = 1)
trainSPlit <- conglomerate[splitIndex,]
testSplit <- conglomerate[-splitIndex,]
imbal_minModel <- randomForest(min ~ .,
trainSPlit,
proximity = TRUE,
ntree = 500, localImp = TRUE)
print(imbal_minModel)
plot(imbal_minModel)
par(pty = 's')
plot.roc(trainSPlit$min, imbal_minModel$votes[,1],legacy.axes=TRUE,
percent = FALSE, print.auc = TRUE,xlab="FALSE POSITIVE",
ylab = 'TRUE POSITIVE')
par(pty = 'm')
splitIndex <- caret::createDataPartition(df_smote$min, p =.7,
list = FALSE,
times = 1)
trainSPlit <- df_smote[splitIndex,]
testSplit <- df_smote[-splitIndex,]
round(prop.table(table(trainSPlit$min)),digits = 3)
round(prop.table(table(testSplit$min)),digits = 3)
ctrl <- caret::trainControl(method = 'cv',
number = 10,
verboseIter = TRUE)
tg <- data.frame(mtry = seq(2,12, by = 1))
minModel <- randomForest(min ~ .,
trainSPlit,
proximity = TRUE,
ntree = 500, localImp = TRUE)
print(minModel)
plot(minModel)
par(pty = 's')
plot.roc(trainSPlit$min, minModel$votes[,1],legacy.axes=TRUE,
percent = FALSE, print.auc = TRUE,xlab="FALSE POSITIVE",
ylab = 'TRUE POSITIVE')
par(pty = 'm')
confusionMatrix(as.factor(trainSplit$min), minModel$votes[,1],positive = 'ORE')
confusionMatrix(as.factor(trainSPlit$min), minModel$votes[,1],positive = 'ORE')
confusionMatrix(as.factor(trainSPlit$min), as.factor(minModel$votes[,1]),positive = 'ORE')
as.factor(minModel$votes[,1])
confusionMatrix(as.factor(trainSPlit$min), as.factor(minModel$predicted),positive = 'ORE')
pred <- predict(minModel, testSplit[,-12])
confusionMatrix(as.factor(testSplit$min), pred,positive = 'ORE')
varImpPlot(minModel,sort = TRUE,scale = TRUE)
varImp(minModel,sort = TRUE,scale = TRUE)
x <- df %>%
filter(ROCK == 'CONGLOMERATE')
y <- df %>%
filter(ROCK == 'CONGLOMERATE') %>%
select(min)
labs <- df %>%
filter(ROCK == 'CONGLOMERATE') %>%
select(ID:LITHO)
pred1 <- predict(minModel, x)
confusionMatrix(as.factor(y$min), as.factor(pred1),positive = 'ORE')
auc1 <- roc(as.double(y$min), as.double(pred1))
plot(auc1, ylim = c(0,1), print.thres = TRUE, main = paste('AUC',round(auc1$auc[[1]],2)))
abline(h=1,col='blue',lwd=2)
abline(h=0,col='red',lwd=2)
## Start by converting the proximity matrix into a distance matrix.
distance.matrix <- as.dist(1-minModel$proximity)
auc1
confusionMatrix(as.factor(y$min), as.factor(pred1),positive = 'ORE')
fromSmote <- BLSMOTE(C = 5,dupSize = 0,
X = as.data.frame(toSmote[,-1]),
K = 5,
target = as.data.frame(toSmote[,'min']))
df_smote <- fromSmote$data %>%
rename(min = class) %>%
mutate(min = as.factor(min))
table(conglomerate$min)
table(toSmote$min)
table(df_smote$min)
splitIndex <- caret::createDataPartition(conglomerate$min, p =.7,
list = FALSE,
times = 1)
trainSPlit <- conglomerate[splitIndex,]
testSplit <- conglomerate[-splitIndex,]
imbal_minModel <- randomForest(min ~ .,
trainSPlit,
proximity = TRUE,
ntree = 500, localImp = TRUE)
print(imbal_minModel)
plot(imbal_minModel)
par(pty = 's')
plot.roc(trainSPlit$min, imbal_minModel$votes[,1],legacy.axes=TRUE,
percent = FALSE, print.auc = TRUE,xlab="FALSE POSITIVE",
ylab = 'TRUE POSITIVE')
par(pty = 'm')
splitIndex <- caret::createDataPartition(df_smote$min, p =.7,
list = FALSE,
times = 1)
trainSPlit <- df_smote[splitIndex,]
testSplit <- df_smote[-splitIndex,]
round(prop.table(table(trainSPlit$min)),digits = 3)
round(prop.table(table(testSplit$min)),digits = 3)
ctrl <- caret::trainControl(method = 'cv',
number = 10,
verboseIter = TRUE)
tg <- data.frame(mtry = seq(2,12, by = 1))
minModel <- randomForest(min ~ .,
trainSPlit,
proximity = TRUE,
ntree = 500, localImp = TRUE)
print(minModel)
plot(minModel)
par(pty = 's')
plot.roc(trainSPlit$min, minModel$votes[,1],legacy.axes=TRUE,
percent = FALSE, print.auc = TRUE,xlab="FALSE POSITIVE",
ylab = 'TRUE POSITIVE')
par(pty = 'm')
confusionMatrix(as.factor(trainSPlit$min), as.factor(minModel$predicted),positive = 'ORE')
pred <- predict(minModel, testSplit[,-12])
confusionMatrix(as.factor(testSplit$min), pred,positive = 'ORE')
varImpPlot(minModel,sort = TRUE,scale = TRUE)
varImp(minModel,sort = TRUE,scale = TRUE)
x <- df %>%
filter(ROCK == 'CONGLOMERATE')
y <- df %>%
filter(ROCK == 'CONGLOMERATE') %>%
select(min)
labs <- df %>%
filter(ROCK == 'CONGLOMERATE') %>%
select(ID:LITHO)
pred1 <- predict(minModel, x)
confusionMatrix(as.factor(y$min), as.factor(pred1),positive = 'ORE')
auc1 <- roc(as.double(y$min), as.double(pred1))
plot(auc1, ylim = c(0,1), print.thres = TRUE, main = paste('AUC',round(auc1$auc[[1]],2)))
abline(h=1,col='blue',lwd=2)
abline(h=0,col='red',lwd=2)
## Start by converting the proximity matrix into a distance matrix.
distance.matrix <- as.dist(1-minModel$proximity)
